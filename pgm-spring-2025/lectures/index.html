<!DOCTYPE html>
<html>

  <head>
  <meta charset="UTF-8">
  <meta http-equiv="content-language" content="en">
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>STAT 479 PGMs | Schedule</title>
  <meta name="description" content="10-708 - Probabilistic Graphical Models - University of Wisconsin-Madison - Spring 2025
">

  <link rel="shortcut icon" href="/pgm-spring-2025/assets/img/favicon.ico">

  <link rel="stylesheet" href="/pgm-spring-2025/assets/css/main.css">
  <link rel="canonical" href="/pgm-spring-2025/lectures/">

  
  <!-- Load Latex JS -->
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.component.js"></script>
  
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <span class="site-title">
      <a class="page-link" href="https://adaptinfer.org/pgm-spring-2025/">STAT 479 PGMs</a>
    </span>

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <a class="page-link" href="/pgm-spring-2025/logistics/">logistics</a>
        <a class="page-link" href="/pgm-spring-2025/lectures/">lectures</a>
        <a class="page-link" href="/pgm-spring-2025/notes/">notes</a>
        <a class="page-link" href="/pgm-spring-2025/calendar/">calendar</a>
        <a class="page-link" href="/pgm-spring-2025/homework/">homework</a>
        <a class="page-link" href="/pgm-spring-2025/project/">project</a>
      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">Schedule</h1>
    <h2 class="post-description"></h2>
  </header>

  <article class="post-content Schedule clearfix">
    <table class="table table-hover">
      <colgroup>
        <col style="width:5%">
        <col style="width:35%">
        <col style="width:45%">
        <col style="width:15%">
      </colgroup>
      <thead class="thead-light">
        <tr>
          <th scope="col">Date</th>
          <th scope="col">Lecture</th>
          <th scope="col">Readings</th>
          <th scope="col">Logistics</th>
        </tr>
      </thead>
      <tbody>
        
<tr class="info">
    <td colspan="5" align="center"><strong>Module 1: Foundations of PGMs and Exact Inference</strong></td>
</tr>

<tr class="past">
    <th scope="row">1/21</th>
    
    <td>
        Lecture #1
        (Prof. Lengerich):
        <br />
        <strong>Course Introduction, Introduction to PGMs</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_01_Intro_to_PGMs.pdf" target="_blank">slides</a>
            
            
            
            | <a href="../notes/lecture-01/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>E. Airoldi, <a href="https://lengerichlab.github.io/pgm-spring-2025/assets/readings/01_Airoldi_GettingStarted.pdf" target="_blank">Getting Started in Probabilistic Graphical Models</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">1/23</th>
    
    <td>
        Lecture #2
        (Prof. Lengerich):
        <br />
        <strong>Statistical Review &amp; Maximum LIkelihood Estimation</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_02_Stats_Review.pdf" target="_blank">slides</a>
            
            
            
            | <a href="../notes/lecture-02/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
    </td>
    <td>
        <p>HW1 Out</p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">1/28</th>
    
    <td>
        Lecture #3
        (Prof. Lengerich):
        <br />
        <strong>A Linear view of Discriminative and Generative Models</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_03_TeX_Discriminative_Generative.pdf" target="_blank">slides</a>
            
            
            
            | <a href="../notes/lecture-03/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>MI. Jordan, Chapter 7</li>
        
            <li>A. Ng, <a href="https://lengerichlab.github.io/pgm-spring-2025/assets/readings/03_ng_generative_discriminative.pdf" target="_blank">On Discriminative vs. Generative Classifiers</a></li>
        
            <li>J. Xue, <a href="https://lengerichlab.github.io/pgm-spring-2025/assets/readings/03_Xue_CommentOn.pdf" target="_blank">Comment on On Discriminative vs. Generative Classifiers</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">1/30</th>
    
    <td>
        Lecture #4
        (Prof. Lengerich):
        <br />
        <strong>Conditional Independence and Directed GMs (BNs)</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_04_BNs.pdf" target="_blank">slides</a>
            
            
            
            | <a href="../notes/lecture-03/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>MI. Jordan, Chapter 2.1</li>
        
            <li>Koller &amp; Friedman, Chapter 3</li>
        
        </ul>
        
    </td>
    <td>
        <p>HW2 Out</p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/4</th>
    
    <td>
        Lecture #5
        (Prof. Lengerich):
        <br />
        <strong>Undirected GMs (MRFs)</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_05_UGMs.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>MI. Jordan, Chapter 2.2</li>
        
            <li>Koller &amp; Friedman, Chapter 4</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/6</th>
    
    <td>
        Lecture #6
        (Prof. Lengerich):
        <br />
        <strong>Exact Inference 1 - Variable Elimination</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_06_Exact_Inference.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>MI. Jordan, Chapter 2.2</li>
        
            <li>Koller &amp; Friedman, Chapter 9</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/11</th>
    
    
    <td colspan="4" align="center">No class (skipped)</td>
    
</tr>

<tr class="past">
    <th scope="row">2/13</th>
    
    
    <td colspan="4" align="center">Quiz</td>
    
</tr>

<tr class="info">
    <td colspan="5" align="center"><strong>Module 2: Learning</strong></td>
</tr>

<tr class="past">
    <th scope="row">2/18</th>
    
    <td>
        Lecture #7
        (Prof. Lengerich):
        <br />
        <strong>Project Ideas + Learning Generalized Linear Models</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_07_GLMs.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>MI. Jordan, Chapter 8, 9.1, 9.2</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/20</th>
    
    <td>
        Lecture #8
        (Prof. Lengerich):
        <br />
        <strong>Parameter Learning in Fully-Observed BNs</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_08_LearningBNs.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Koller &amp; Friedman, Chapter 17.1-17.4</li>
        
        </ul>
        
    </td>
    <td>
        <p>HW3 Out</p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/25</th>
    
    <td>
        Lecture #9
        (Prof. Lengerich):
        <br />
        <strong>Learning Undirected GMs</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_09_LearningUGMs.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Z. Ghahramani, <a href="https://lengerichlab.github.io/pgm-spring-2025/assets/readings/09_Gharamani_Learning.pdf" target="_blank">Graphical models parameter learning</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">2/27</th>
    
    <td>
        Lecture #10
        (Prof. Lengerich):
        <br />
        <strong>Structure Learning</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_10_StructureLearning.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>S. Ermon, <a href="https://ermongroup.github.io/cs228-notes/learning/structure/" target="_blank">Structure learning for Bayesian networks</a></li>
        
            <li>M. Scutari, <a href="https://lengerichlab.github.io/pgm-spring-2025/assets/readings/10_Scutari_WhoLearnsBetter.pdf" target="_blank">Who Learns Better Bayesian Network Structures</a></li>
        
            <li>X. Zheng, <a href="https://proceedings.neurips.cc/paper/2018/hash/e347c51419ffb23ca3fd5050202f9c3d-Abstract.html" target="_blank">DAGs with NO TEARS</a></li>
        
        </ul>
        
    </td>
    <td>
        <p>HW4 Out</p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">3/4</th>
    
    <td>
        Lecture #11
        (Prof. Lengerich):
        <br />
        <strong>Causal Discovery</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_11_Causality.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>K. Zhang, <a href="https://lengerichlab.github.io/pgm-spring-2025/assets/readings/11_Zhang_Learning.pdf">Learning causality and causality-related learning</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">3/6</th>
    
    <td>
        Lecture #12
        (Prof. Lengerich):
        <br />
        <strong>Parameter Learning of partially observed BNs</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_12_EM.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>MI. Jordan, Chapter 11</li>
        
            <li>Koller &amp; Friedman, Chapter 19.1-19.4</li>
        
        </ul>
        
    </td>
    <td>
        <p>HW5 Out</p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">3/11</th>
    
    <td>
        Lecture #13
        (Prof. Lengerich):
        <br />
        <strong>Variational Inference</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_13_Variational.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>MI. Jordan, Chapter 15</li>
        
            <li>D. Blei, <a href="https://www.cs.columbia.edu/~blei/talks/Blei_VI_tutorial.pdf" target="_blank">Variational Inference Foundations and Innovations</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">3/13</th>
    
    <td>
        Lecture #14
        (Prof. Lengerich):
        <br />
        <strong>Monte Carlo</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_14_MC.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>MacKay, Chapter 29</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">3/18</th>
    
    <td>
        Lecture #15
        (Prof. Lengerich):
        <br />
        <strong>Review</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_15_Review.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">3/20</th>
    
    
    <td colspan="4" align="center">Exam</td>
    
</tr>

<tr class="past">
    <th scope="row">3/25</th>
    
    
    <td colspan="4" align="center">No class (Spring recess)</td>
    
</tr>

<tr class="past">
    <th scope="row">3/27</th>
    
    
    <td colspan="4" align="center">No class (Spring recess)</td>
    
</tr>

<tr class="info">
    <td colspan="5" align="center"><strong>Module 3: Modern Probabilistic AI</strong></td>
</tr>

<tr class="past">
    <th scope="row">4/1</th>
    
    <td>
        Lecture #16
        (Prof. Lengerich):
        <br />
        <strong>Deep Learning from a GM Perspective</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_16_DL_Intro.pdf" target="_blank">slides</a>
            
            
            
            | <a href="../notes/lecture-16/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Goodfellow et al., <a href="http://www.deeplearningbook.org/">Deep learning book</a>, Ch. 6.2-5, 20.3-4</li>
        
            <li>Salakhutdinov and Hinton, <a href="https://proceedings.mlr.press/v5/salakhutdinov09a.html">Deep Boltzmann Machines</a></li>
        
            <li>Ranganath et al., <a href="https://arxiv.org/abs/1411.2581">Deep exponential families</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">4/3</th>
    
    <td>
        Lecture #17
        (Prof. Lengerich):
        <br />
        <strong>CNNs, RNNs, Autoencoders</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_17_CNN_RNN_Autoencoders.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Pascanu, Mikolov, Bengio, <a href="http://proceedings.mlr.press/v28/pascanu13.pdf">On the difficulty of training recurrent neural networks</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">4/8</th>
    
    <td>
        Lecture #18
        :
        <br />
        <strong>Deep Generative Models: GAN, VAEs</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_18_DGMs.pdf" target="_blank">slides</a>
            
            
            
            | <a href="../notes/lecture-18/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Goodfellow et al., <a href="http://www.deeplearningbook.org/">Deep learning book</a>, Ch. 20.9-10</li>
        
            <li>Kingma and Welling, <a href="https://arxiv.org/abs/1312.6114">Variational Autoencoders</a></li>
        
            <li>Goodfellow et al., <a href="http://papers.nips.cc/paper/5423-generative-adversarial-nets">Generative Adversarial Nets</a></li>
        
            <li>Arora., <a href="http://www.offconvex.org/2017/03/15/GANs/">Generative Adversarial Networks (GANs), Some Open Questions</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">4/10</th>
    
    <td>
        Lecture #19
        (Prof. Lengerich):
        <br />
        <strong>Attention and Transformers</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_19_Attention.pdf" target="_blank">slides</a>
            
            
            
            | <a href="../notes/lecture-19/" target="_blank">notes</a>
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Vasvani et al., <a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need</a></li>
        
            <li>Devlin et al., <a href="https://arxiv.org/pdf/1810.04805.pdf">BERT - Pre-training of Deep Bidrectional Transformers for Language Understanding.</a></li>
        
            <li>Raschka, <a href="https://www.youtube.com/watch?v=-Ll8DtpNtvk&amp;list=PLTKMiZHVd_2Licpov-ZK24j6oUnbhiPkm&amp;index=2">Build an LLM from Scratch 3</a> (video)</li>
        
            <li>Sanderson, <a href="https://www.youtube.com/watch?v=KJtZARuO3JY">Visualizing transformers and attention</a> (video)</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">4/15</th>
    
    <td>
        Lecture #20
        (Prof. Lengerich):
        <br />
        <strong>LLMs from a Probabilistic Perspective 1: Implementing a GPT from Scratch</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_20_GPT.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Radford et al., <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf">Improving Language Understanding by Generative Pre-Training</a> (the GPT-1 paper)</li>
        
            <li>Radford et al., <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Language Models are Unsupervised Multitask Learners</a> (the GPT-2 paper)</li>
        
            <li>Brown et al., <a href="https://arxiv.org/abs/2005.14165">Language Models are Few-Shot Learners</a> (the GPT-3 paper)</li>
        
            <li>Raschka, <a href="https://www.youtube.com/watch?v=YSAkgEarBGE&amp;list=PLTKMiZHVd_2Licpov-ZK24j6oUnbhiPkm">Build an LLM from Scratch 4</a> (video)</li>
        
            <li>Karpathy, <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY">Let's Build GPT from Scratch </a>(video)</li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">4/17</th>
    
    <td>
        Lecture #21
        (Prof. Lengerich):
        <br />
        <strong>LLMs from a Probabilistic Perspective 2: Training on Unlabeled Data</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_21_LLMs_Unsupervised.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Bi. et al, <a href="https://arxiv.org/abs/2401.02954">DeepSeek LLM Scaling Open-Source Language Models with Longtermism</a></li>
        
            <li>Liu et al., <a href="https://arxiv.org/abs/2405.04434">DeepSeekV2 A Strong, Economical, and Efficient Mixture-of-Experts Language Model</a></li>
        
            <li>Liu et al., <a href="https://arxiv.org/abs/2412.19437">DeepSeekV3 Technical Report</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">4/22</th>
    
    <td>
        Lecture #22
        (Prof. Lengerich):
        <br />
        <strong>LLMs from a Probabilistic Perspective 3: Fine-tuning on Labeled Data</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_22_LLMs_Supervised.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Raffel et al., <a href="https://arxiv.org/abs/1910.10683">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</a></li>
        
            <li>Ouyang et al., <a href="https://arxiv.org/abs/2203.02155">Training language models to follow instructions with human feedback</a></li>
        
            <li>Li &amp; Liang, <a href="https://arxiv.org/abs/2101.00190">Prefix-tuning - Optimizing continuous prompts for generation</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">4/24</th>
    
    <td>
        Lecture #23
        (Prof. Lengerich):
        <br />
        <strong>New Directions in connecting LLMs to Graphical Models</strong>

        <br />
        [
            
              <a href="../assets/lectures/Lecture_23_Context.pdf" target="_blank">slides</a>
            
            
            
            | notes
            
        ]
    </td>
    <td>
        
        <ul>
        
            <li>Lengerich et al., <a href="https://arxiv.org/abs/2310.11340">Contextualized Machine Learning</a></li>
        
        </ul>
        
    </td>
    <td>
        <p></p>
    </td>
    
</tr>

<tr class="past">
    <th scope="row">4/29</th>
    
    
    <td colspan="4" align="center">Project Presentations</td>
    
</tr>

<tr class="past">
    <th scope="row">5/1</th>
    
    
    <td colspan="4" align="center">Project Presentations</td>
    
</tr>


      </tbody>
    </table>
  </article>

</div>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Introduction to Probabilistic Graphical Models and Modern Probabilistic AI</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ben Lengerich</li><li><a class="u-email" href="mailto:TBD@wisc.edu">TBD@wisc.edu</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/AdaptInfer" target="_blank"><i class="fab fa-github"></i> <span class="username">AdaptInfer</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>&copy; Copyright 2025 University of Wisconsin. <br />
        Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
</p>
      </div>
    </div>

  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/pgm-spring-2025/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.js"></script>
<script src="/pgm-spring-2025/assets/js/katex.js"></script>



<!-- Load Anchor JS -->
<script src="//cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.2/anchor.min.js"></script>
<script>
  anchors.options.visible = 'hover';
  anchors.add('article h2, article h3, article h4, article h5, article h6');
</script>



<!-- Adjust LaTeX JS -->
<script src="/pgm-spring-2025/assets/js/latex.js"></script>


<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/pgm-spring-2025/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/pgm-spring-2025/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
