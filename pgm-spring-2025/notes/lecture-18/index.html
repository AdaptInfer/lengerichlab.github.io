<!DOCTYPE html>
<html>
  <head>
    <head>
  <meta charset="UTF-8">
  <meta http-equiv="content-language" content="en">
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>STAT 479 PGMs | Lecture 18 - Deep Generative Models</title>
  <meta name="description" content="10-708 - Probabilistic Graphical Models - University of Wisconsin-Madison - Spring 2025
">

  <link rel="shortcut icon" href="/pgm-spring-2025/assets/img/favicon.ico">

  <link rel="stylesheet" href="/pgm-spring-2025/assets/css/main.css">
  <link rel="canonical" href="/pgm-spring-2025/notes/lecture-18/">

  
  <!-- Load Latex JS -->
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/latex.js@0.11.1/dist/latex.component.js"></script>
  
</head>

    <script src="/pgm-spring-2025/assets/js/distillpub/template.v2.js"></script>
    <script src="/pgm-spring-2025/assets/js/distillpub/transforms.v2.js"></script>
  </head>

  <d-front-matter>
    <script type="text/json">{
      "title": "Lecture 18 - Deep Generative Models",
      "description": "Introduction to Variational Autoencoders, Generative Adversarial Networks, and Diffusion Models.",
      "published": "April 8, 2025",
      "lecturers": [
        
        {
          "lecturer": "Ben Lengerich",
          "lecturerURL": "https://lengerichlab.github.io/"
        }
        
      ],
      "authors": [
        
        {
          "author": "Wenyu Dai"
        },
        
        {
          "author": "Oliver Max Hannagan"
        },
        
        {
          "author": "David Giardino"
        }
        
      ],
      "editors": [
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body>

    <header class="site-header">

  <div class="wrapper">

    <span class="site-title">
      <a class="page-link" href="https://adaptinfer.org/pgm-spring-2025/">STAT 479 PGMs</a>
    </span>

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <a class="page-link" href="/pgm-spring-2025/logistics/">logistics</a>
        <a class="page-link" href="/pgm-spring-2025/lectures/">lectures</a>
        <a class="page-link" href="/pgm-spring-2025/notes/">notes</a>
        <a class="page-link" href="/pgm-spring-2025/calendar/">calendar</a>
        <a class="page-link" href="/pgm-spring-2025/homework/">homework</a>
        <a class="page-link" href="/pgm-spring-2025/project/">project</a>
      </div>
    </nav>

  </div>

</header>



    <div class="page-content">

      <d-title>
        <h1>Lecture 18 - Deep Generative Models</h1>
        <p>Introduction to Variational Autoencoders, Generative Adversarial Networks, and Diffusion Models.</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <h2 id="logistics-review">Logistics Review</h2>

<ul>
  <li><strong>Class webpage</strong>: <a href="https://lengerichlab.github.io/pgm-spring-2025">lengerichlab.github.io/pgm-spring-2025</a></li>
  <li><strong>Instructor</strong>: Ben Lengerich
    <ul>
      <li>Office Hours: Thursday 3:30-4:30pm, 7278 Medical Sciences Center</li>
      <li>Email: <a href="mailto:lengerich@wisc.edu">lengerich@wisc.edu</a></li>
    </ul>
  </li>
  <li><strong>TA</strong>: Chenyang Jiang
    <ul>
      <li>Office Hours: Monday 11am-12pm, 1219 Medical Sciences Center</li>
      <li>Email: <a href="mailto:cjiang77@wisc.edu">cjiang77@wisc.edu</a></li>
    </ul>
  </li>
</ul>

<h2 id="deep-generative-models">Deep Generative Models</h2>

<h3 id="recall-generative-and-discriminative-models">Recall Generative and Discriminative models</h3>

<ul>
  <li>
    <p>Generative:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. model joint distribution P(X,Y)
2. Observe X and Y. Learn P(X|Y) and P(Y).
3. Calculate P(X) by integrating P(X,Y) over Y, and eventually gets P(Y|X)
</code></pre></div>    </div>

    <ul>
      <li>Example: Naive Bayes</li>
    </ul>
  </li>
  <li>
    <p>Discriminative:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1. model conditional distribution P(Y|X)
2. Observe X and Y and learn P(Y|X)
</code></pre></div>    </div>

    <ul>
      <li>Example: logistic regression</li>
    </ul>
  </li>
</ul>

<h3 id="what-are-deep-generative-models">What are Deep Generative Models?</h3>

<ul>
  <li>Deep means many layers: $Z_{1}\to …\to Z_{k}\to X$</li>
  <li>Define probablistic distributions over a set of variables.</li>
</ul>

<h2 id="early-forms-of-dgms">Early Forms of DGMs:</h2>

<figure id="sigmoidBelief" class="l-body-outset">
<div class="row">
  <div class="col three">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-17/sigmoid_belief_net.png" style="width:80%; max-width:800px;" />
  </div>
</div>
</figure>

<p>A Probablistic nerual network that uses sigmoid activation functiona to model conditional probabilities. It uses directed edges where nodes are consisted of binary values.</p>

<figure id="helmholtz_machine" class="l-body-outset">
<div class="row">
  <div class="col three">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-17/helmholtz_machine.png" style="width:80%; max-width:800px;" />
  </div>
</div>
</figure>

<p>Helmholtz machine has two networks as seen in the graph above. One is bottom-up that takes inputs and produces distributions over hidden layers. Another is top-down that generates values.</p>

<h2 id="how-dgms-are-trained">How DGMs are trained?</h2>

<ul>
  <li>Via EM framework:
    <ul>
      <li><strong>E-step (Expectation):</strong> Estimate the posterior distribution of the latent variables given the observed data.</li>
      <li><strong>M-step (Maximization):</strong> Maximize the expected log-likelihood with respect to model parameters.</li>
    </ul>
  </li>
  <li>Sampling and Data Augmentation:
    <ul>
      <li>Ancestral sampling (for autoregressive models)</li>
      <li>Gibbs sampling (for undirected models)</li>
    </ul>
  </li>
  <li>Variational Inference:
    <ul>
      <li>Replace the true posterior with a simpler distribution.</li>
      <li>Used in models like Variational Autoencoders.</li>
      <li>Optimize the Evidence Lower Bound (ELBO):</li>
    </ul>
  </li>
</ul>

\[\log p(x) \geq \mathbb{E}_{q(z \mid x)}\left[ \log p(x \mid z) \right] - \mathrm{KL}\left( q(z \mid x) \,\|\, p(z) \right)\]

<ul>
  <li>Wake and Sleep Algorithm:
    <ul>
      <li><strong>Wake phase:</strong>
        <ul>
          <li>Use real data to update the generative model.</li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>$E_{q(z</td>
                  <td>x)}[\log p(x</td>
                  <td>z)]$</td>
                </tr>
              </tbody>
            </table>
          </li>
        </ul>
      </li>
      <li><strong>Sleep phase:</strong>
        <ul>
          <li>Use generated data to train the inference model.</li>
          <li>
            <table>
              <tbody>
                <tr>
                  <td>$E_{q(x</td>
                  <td>z)}[\log p(z</td>
                  <td>x)]$</td>
                </tr>
              </tbody>
            </table>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="variational-autoencoders-vaes">Variational Autoencoders (VAEs)</h2>

<h3 id="vaes-is-variational-inference-plus-autoencoders">VAEs is variational inference plus autoencoders</h3>

<table>
  <tbody>
    <tr>
      <td>Recall ELBO of VI where we let q(z</td>
      <td>x) be some family that’s easier to optimize:</td>
    </tr>
  </tbody>
</table>

\[\log p(x) \geq E_{z \sim q(z)}[\log p(x, z)] + H(q)\]

<p>Also, recall autoencoder:</p>
<ol>
  <li>Use encoder to compress data into smaller details.</li>
  <li>Pass through latent space.</li>
  <li>Use decoder to recreate the original input.</li>
</ol>

<figure id="vae" class="l-body-outset">
<div class="row">
  <div class="col three">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-17/vae.png" style="width:80%; max-width:800px;" />
  </div>
</div>
</figure>

<p>The idea here is simple. Autoencoder is not generative but we can make it generative by using variational inference.
We can use the inference model as encoder. Pass the generated data to letent space Z, and decode the data using generative model.</p>

<p>Now, we want to estimate the true parameter of θ of the generative model. The question is how to represent it?</p>
<ol>
  <li>We can chose a simple prior p(z) like normal distribution.</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Then we can train the model by maximizing the likelehood of training data: $p_{\theta}(x) = \int_{}^{}p_{\theta}(z)p_{\theta}(x</td>
          <td>z)dz$</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<h3 id="reparameterization-trick">Reparameterization Trick</h3>

<p>To enable backpropagation through stochastic sampling, VAEs use the <strong>reparameterization trick</strong>:</p>

\[z = \mu(x) + \sigma(x) \cdot \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)\]

<p>This reformulation allows gradients to flow through ( \mu(x) ) and ( \sigma(x) ), making the sampling operation differentiable and trainable with gradient descent.</p>

<h3 id="generating-from-a-vae">Generating from a VAE</h3>

<p>After training, you can generate new data as follows:</p>
<ol>
  <li>Sample a latent vector ( z \sim p(z) ), often a standard Gaussian.</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>Pass ( z ) through the decoder to get ( x’ \sim p(x</td>
          <td>z) ).</td>
        </tr>
      </tbody>
    </table>
  </li>
</ol>

<p>This enables the model to create novel data that resembles the training distribution.</p>

<h3 id="gan-architecture-and-objective">GAN Architecture and Objective</h3>
<p>GANs consist of:</p>
<ul>
  <li>A <strong>Generator</strong> ( G(z) ): maps random noise ( z \sim p(z) ) to data space, producing fake samples.</li>
  <li>A <strong>Discriminator</strong> ( D(x) ): attempts to distinguish real data from fake data.</li>
</ul>

<p>The generator learns to fool the discriminator; the discriminator learns to detect the fakes. Training is formulated as a minimax game:</p>

\[\min_G \max_D \; \mathbb{E}_{x \sim p_{\text{data}}}[\log D(x)] + \mathbb{E}_{z \sim p(z)}[\log(1 - D(G(z)))]\]

<table>
  <tbody>
    <tr>
      <td>This adversarial setup allows GANs to learn a rich, implicit distribution over data without explicitly modeling ( p(x</td>
      <td>z) ).</td>
    </tr>
  </tbody>
</table>

<h2 id="generative-adversarial-networks-gans">Generative Adversarial Networks (GANs)</h2>

<p><strong>Key Points</strong>:</p>
<ul>
  <li>Generative Adversarial Networks (GANs) provide a framework where two models (Generator and Discriminator) are trained simultaneously in a minimax game.</li>
  <li>The <strong>Generator</strong> attempts to produce samples that mimic the true data, while the <strong>Discriminator</strong> attempts to distinguish between real and fake samples.</li>
  <li>This process eventually yields a Generator that can produce highly realistic samples.</li>
  <li>The data distribution is “implicit”: meaning $p(x)$ isn’t parameterized directly.</li>
  <li>Sampling a latent variable $\mathbf{z}$ from a prior $\mathcal{N}(0,I)$ and mapping it through a generator $G(\mathbf{z})$ is done to obtain synthetic samples $\mathbf{x}$.</li>
  <li><strong>Notation</strong>:
    <ul>
      <li>$\mathbf{x} \sim p_{\text{data}}(\mathbf{x})$</li>
      <li>$\mathbf{x} = G(\mathbf{z}); \quad \mathbf{z} \sim p(\mathbf{z})$</li>
    </ul>
  </li>
  <li>The <strong>Generator</strong> $G$ tries to transform noise $\mathbf{z}$ into data-like samples.</li>
  <li>The <strong>Discriminator</strong> $D$ evaluates whether a sample is real or generated.</li>
  <li><strong>Training objective</strong>:</li>
</ul>

<figure id="Training objective" class="l-body-outset">
<div class="row">
  <div class="col">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-18/slide44.png" style="width:80%; max-width:600px;" />
  </div>
</div>
<figcaption>
  <strong>Slide 43:</strong> Training objective.
</figcaption>
</figure>

<figure id="GANs" class="l-body-outset">
<div class="row">
  <div class="col">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-18/slide43.png" style="width:80%; max-width:600px;" />
  </div>
</div>
<figcaption>
  <strong>Slide 43:</strong> Outline of the generator-discriminator framework.
</figcaption>
</figure>

<ul>
  <li>The discriminator’s loss provides a training signal for the generator and therefore no explicit likelihood function is needed.</li>
  <li>Potential challenges:
    <ul>
      <li><em>Training instability</em> due to the minimax setup.</li>
      <li><em>Mode collapse</em> where the generator produces a narrow set of outputs.</li>
    </ul>
  </li>
  <li>DCGANs (Deep Convolutional GANs) produce realistic-looking images, illustrating how powerful adversarial training can be for generating image data.</li>
</ul>

<figure id="GAN example result" class="l-body-outset">
<div class="row">
  <div class="col">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-18/slide45.png" style="width:80%; max-width:600px;" />
  </div>
</div>
<figcaption>
  <strong>Slide 45:</strong> Example Results.
</figcaption>
</figure>

<h2 id="gans-and-vaes-a-unified-view">GANs and VAEs: A Unified View</h2>

<p><strong>Key Points</strong>:</p>
<ul>
  <li>Both are deep generative models but differ in how they learn:
    <ul>
      <li><strong>VAEs</strong>: learn an <em>explicit</em> density by maximizing ELBO.</li>
      <li><strong>GANs</strong>: learn an <em>implicit</em> density via adversarial training.</li>
    </ul>
  </li>
  <li>There have been attempts to combine these approaches (e.g., VAE-GAN hybrids).</li>
</ul>

<figure id="GAN" class="l-body-outset">
<div class="row">
  <div class="col">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-18/slide47.png" style="width:80%; max-width:600px;" />
  </div>
</div>
<figcaption>
  <strong>Slide 47:</strong> GANs Revisited.
</figcaption>
</figure>

<ul>
  <li>Generator parameters define a mapping from latent space $\mathbf{z}$ to data space $\mathbf{x}$.</li>
  <li>The model distribution is implicitly defined by the transformation $G$ and the prior on $\mathbf{z}$.</li>
</ul>

<h2 id="variational-em-vs-gans">Variational EM vs GANs</h2>

<p><strong>Key Points</strong>:</p>
<ul>
  <li>The <strong>Discriminator</strong> can be viewed as a variational distribution $q_\phi(y \mid \mathbf{x})$, distinguishing real vs. generated.</li>
  <li>The <strong>Generator</strong> is used to a model that samples $\mathbf{x}$ by $\mathbf{x} = G(\mathbf{z}), \mathbf{z}\sim p(\mathbf{z})$.</li>
  <li>This interpretation draws parallels to EM, but the discriminator and generator have separate objectives.</li>
</ul>

<figure id="Rewrite GAN in VAE" class="l-body-outset">
<div class="row">
  <div class="col">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-18/slide48.png" style="width:80%; max-width:600px;" />
  </div>
</div>
<figcaption>
  <strong>Slide 48:</strong> GANs rewritten.
</figcaption>
</figure>

<figure id="GAN vs VAE" class="l-body-outset">
<div class="row">
  <div class="col">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-18/slide50.png" style="width:80%; max-width:600px;" />
  </div>
</div>
<figcaption>
  <strong>Slide 50:</strong> GANs vs VAEs.
</figcaption>
</figure>

<ul>
  <li><strong>Variational EM</strong>:
    <ul>
      <li>Single objective for both model ($\theta$) and variational distribution ($\phi$).</li>
      <li>Extra prior regularization from $p(\mathbf{z})$.</li>
      <li>
        <table>
          <tbody>
            <tr>
              <td>Has a “reconstruction” term: it explicitly maximizes $\log p(x \mid z)$ with $z \sim q(z</td>
              <td>x)$.</td>
            </tr>
          </tbody>
        </table>
      </li>
    </ul>
  </li>
  <li><strong>GAN</strong>:
    <ul>
      <li>Two objectives: the generator wants to fool the discriminator, and the discriminator wants to detect fakes.</li>
      <li>No explicit prior penalty on $z$ for the reconstruction itself—rather, $z$ is drawn from $p(\mathbf{z})$.</li>
      <li>Minimizes an adversarial loss instead of a direct $\log p(x\mid z)$ objective.</li>
    </ul>
  </li>
</ul>

<figure id="Mode covering vs missing" class="l-body-outset">
<div class="row">
  <div class="col">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-18/slide51.png" style="width:80%; max-width:600px;" />
  </div>
</div>
<figcaption>
  <strong>Slide 51:</strong> Mode Covering vs Mode dropping (mode collapse).
</figcaption>
</figure>

<ul>
  <li>VAEs can produce more “blurry” but comprehensive coverage (mode covering).</li>
  <li>GANs produce sharper images but risk missing entire modes (mode dropping).</li>
</ul>

<h2 id="diffusion-models">Diffusion Models</h2>

<p><strong>Key Idea</strong>:</p>
<ul>
  <li>The forward process adds noise to data step-by-step, destroying structure.</li>
  <li>The backward process progressively denoises, reconstructing data from pure noise.</li>
  <li>
    <p>These models are known for producing extremely high-fidelity generated samples (images, etc.).</p>
  </li>
  <li><strong>Training</strong>:
    <ul>
      <li>Often framed as predicting the added noise at each step, similar to a score-matching approach.</li>
      <li>Once trained, sampling involves reversing the noise steps to create data-like samples from random noise.</li>
    </ul>
  </li>
</ul>

<figure id="Backward Process" class="l-body-outset">
<div class="row">
  <div class="col">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-18/slide53.png" style="width:80%; max-width:600px;" />
  </div>
</div>
<figcaption>
  <strong>Slide 53:</strong> Diffusion Model: Backward Process.
</figcaption>
</figure>

<figure id="Forward Process" class="l-body-outset">
<div class="row">
  <div class="col">
    <img src="/pgm-spring-2025/assets/img/notes/lecture-18/slide54.png" style="width:80%; max-width:600px;" />
  </div>
</div>
<figcaption>
  <strong>Slide 54:</strong> Diffusion Model: Forward Process.
</figcaption>
</figure>


      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">Introduction to Probabilistic Graphical Models and Modern Probabilistic AI</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Ben Lengerich</li><li><a class="u-email" href="mailto:TBD@wisc.edu">TBD@wisc.edu</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/AdaptInfer" target="_blank"><i class="fab fa-github"></i> <span class="username">AdaptInfer</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>&copy; Copyright 2025 University of Wisconsin. <br />
        Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

  <d-bibliography src="/pgm-spring-2025/assets/bibliography/2025-04-08-lecture-18.bib">
  </d-bibliography>

  <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/pgm-spring-2025/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.1/katex.min.js"></script>
<script src="/pgm-spring-2025/assets/js/katex.js"></script>



<!-- Load Anchor JS -->
<script src="//cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.2/anchor.min.js"></script>
<script>
  anchors.options.visible = 'hover';
  anchors.add('article h2, article h3, article h4, article h5, article h6');
</script>



<!-- Adjust LaTeX JS -->
<script src="/pgm-spring-2025/assets/js/latex.js"></script>


<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/pgm-spring-2025/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/pgm-spring-2025/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', '', 'auto');
ga('send', 'pageview');
</script>


</html>
